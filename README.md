# requirements
1. benchmark various inference-time scaling methods for LLM on several benchmarks: 
   - AIME 2025
   - HLE
   - GPQA
   - HMMT 2025
   - LiveCodeBench
   - MMMU/MMLU
2. need to be able to easily test various LLMs (qwen, deepseek, claude, gpt, gemini, etc.)
3. log price, tokens inputted and outputted, number of forward passes, response time, etc.